"""
    Questions
"""
1. Will it be better to implement PPO from scratch rather than initializing it from a stable-baselines3 library?
2. What hyperparameters improve the performance?
3. How many tries in average takes a trained model to complate a lap in the evaluation step?
4. Does a car trained in X circuit transfer equally to Y circuit in terms of performance? Or does it matter where is trained?
5. What does the literature say about model-free algorithms being capable of transfer learning? Only applies to model-based?
6. What kind of reward engineer improves the performance? Based on vision, or declaration of specific steering and velocity actions?
7. Why does it start by fast, and progressively slows down until reach a plateau around 58 mph (Fictional)?
8. Can I train a model on different circuits on the same step?



"""
    Annotations
"""
2. Record performance across different circuits.
3. Reward engineer the system by setting fixed velocity and steering angles.
4. Record average velocity for laps where circuit is completed.
5. TODO: Read  difference between TRPO, Maskable PPO, RecurrentPPO (PPO LSTM). Check if they improve performance.
    - Need to install other repo from sb3: https://stable-baselines3.readthedocs.io/en/master/guide/sb3_contrib.html LINK
6. Read about KL divergence.


"""
    DONE TASKS
"""
1. Implement a way of recording percentage of lap completed.


"""
    Evaluation Runs
"""

    TRPO (Trained on Catalunya)

    AUSTIN
    Per-Episode Rewards 
    [605.90451, 10671.868544, 1.88959, 19.264524, 20790.324017, 4529.813422, 5737.419552, 17508.632294, 11070.169443, -0.94439]
    [-2, 10528.857164, 10609.995245, 25363.240572, 31992.592375, 1.88959, 5338.379837, 4395.040344, 606.673129, 10569.238624]
    [6063.592044, 669.806136, 834.444555, 4413.124641, -2, 4373.354931, 10543.150364, 6067.658804, 10500.596268, 2.14636]
    
    Per-Episode Length (n_steps) (Around 3000 is one lap completed)
    [116, 1657, 8, 16, 3077, 702, 902, 2616, 1698, 4]
    [1, 1594, 1594, 3664, 4522, 8, 833, 670, 116, 1598]
    [941, 131, 155, 674, 1, 669, 1596, 947, 1595, 9]


    CATALUNYA
    Per-Episode Rewards
    [2248.969506, 42411.035708, 2224.0436, 2254.47521, 2170.571716, 4895.129525, 42448.99835, 22258.790393, 2231.014854, 22242.351018]
    [2064.418135, 2133.871597, 2255.607374, 2264.49451, 2209.909718, 26857.262179, 2076.135411, 42414.399132, 2216.424719, 42499.936]
    [4910.958054, 22195.868259, 2181.810096, 31993.826267, 25439.059226, 2262.399112, 2258.20456, 26855.647323, 2049.965403, 21501.621498]

    Per-Episode Length (n_steps) (5700 two laps, 2600 -> one lap)
    [363, 5737, 361, 364, 346, 749, 5736, 3197, 353, 3200]
    [332, 340, 355, 369, 352, 3501, 319, 5740, 347, 5745]
    [744, 3185, 338, 4432, 3603, 365, 369, 3519, 332, 2835]

    TRACK_1
    Per-Episode Rewards
    [7503.396588, 3555.004788, 5254.192557, 64.537229, 2855.803387, 42.096719, 34.623488, 7415.355404, 28.971437, 46.697009]
    [7462.104987, 7386.11559, 7532.888241, 12937.301831, 8635.609831, 7399.738854, 523.254364, 7515.345219, 7497.218586, 12860.259998]
    [6670.511431, 2851.300622, 6852.305588, 3542.098475, 2863.716431, 12726.577234, 7010.52456, 6864.767115, 7336.444091, 7339.055501]

    Per-Episode Length (n_steps) 
    [1145, 556, 802, 32, 444, 23, 25, 1141, 19, 24]
    [1138, 1145, 1134, 1900, 1362, 1161, 100, 1145, 1146, 1902]
    [1027, 437, 1056, 553, 433, 1875, 1069, 1050, 1156, 1156]

    TRACK_2
    Per-Episode Rewards
    [17936.539262, 6312.231535, 10518.601848, 6372.998524, 6546.086264, 6326.796329, 4780.888508, 17641.012383, 17710.623488, 10274.673348]
    [11559.016402, 11519.462131, 2867.114778, 17780.264664, 15694.657793, 15879.492504, 9438.153739, 15340.973104, 17595.068835, 10422.458657]
    [17751.850509, 6477.88005, 17437.432278, 17848.273306, 6552.55518, 11463.419386, 17842.975207, 17787.597576, 17841.928068, 3161.95598]

    Per-Episode Length (n_steps) 
    [2468, 972, 1410, 977, 1003, 963, 727, 2465, 2461, 1512]
    [1701, 1671, 458, 2474, 2197, 2223, 1425, 2154, 2483, 1526]
    [2462, 979, 2438, 2463, 1000, 1672, 2460, 2459, 2465, 513]


    PPO - 16 (Trained on Catalunya)
    Austin
    Per-Episode Rewards
    [-2, 648.80129, 4474.771678, 5507.611476, 4501.014038, 4459.039455, 25.288701, 609.720134, 4504.762477, 618.713338]
    [644.082056, 4535.660378, 661.404365, 4497.621825, 655.632451, 640.959983, 642.363894, -0.94439, 6249.038332, 4563.891348]
    [10721.776317, 6283.210592, 20.986011, 672.992235, 4486.048247, -0.94439, 678.821377, 10795.730576, 10914.596831, 6393.953895]

    Per-Episode Length (n_steps)
    [1, 116, 672, 827, 671, 674, 18, 109, 674, 110]
    [114, 675, 121, 697, 116, 116, 114, 4, 952, 682]
    [1612, 973, 20, 118, 679, 4, 120, 1619, 1642, 999]


    PPO - 11 (Track1)

    Austin
    Per-Episode Rewards
    [586.46742, 4495.364165, 10731.673771, 4536.570273, 684.576536, 4369.673724, 704.497973, 4463.627225, 596.651127, 6325.704058]
    [4487.158343, 34.876282, 4526.114582, 622.126355, 647.734895, 5515.025036, 4471.095488, 4401.126526, 4554.202874, 5458.14881]
    [4479.429138, 4541.661274, 4487.241937, 682.746635, 643.020208, 6214.422482, 638.740058, 10690.026159, 6262.74735, 4494.76118]
    

    Per-Episode Length (n_steps)
    [106, 679, 1633, 705, 121, 678, 123, 672, 113, 952]
    [684, 32, 687, 114, 121, 850, 672, 669, 703, 852]
    [674, 678, 687, 120, 116, 953, 119, 1609, 949, 679]


    PPO - 15 (Track2)

    Austin
    Per-Episode Rewards
    [49.83901, 4498.947531, 581.772521, 4510.516004, 4523.185709, 4395.92692, 641.3723, 697.528889, 5553.364084, 4438.271172]
    [8.24227, 5562.072938, 17.49512, 629.866054, 622.066063, 5551.857145, 10859.095217, 647.981213, 4360.082379, 26.61559]
    [-0.94439, 4473.210903, 614.988557, 671.584815, 4452.4692, 682.227071, 4502.494942, 4507.083036, 4459.998102, 4439.367444]

    Per-Episode Length (n_steps)
    [24, 687, 114, 684, 684, 676, 114, 124, 849, 687]
    [12, 857, 15, 119, 118, 839, 1643, 117, 679, 18]
    [4, 684, 121, 120, 682, 120, 685, 682, 677, 682]
    

